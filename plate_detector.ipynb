{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,\\\n",
    "                                    Conv2D,\\\n",
    "                                    MaxPooling2D,\\\n",
    "                                    Dropout,\\\n",
    "                                    Flatten\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,\\\n",
    "                                       ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Class</th>\n",
       "      <th>FileName</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[69, 73, 78], [73, 77, 82], [74, 78, 83], [7...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.bmp</td>\n",
       "      <td>144</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[116, 117, 121], [116, 117, 121], [116, 115,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.bmp</td>\n",
       "      <td>76</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[57, 58, 56], [57, 58, 56], [64, 65, 63], [7...</td>\n",
       "      <td>0</td>\n",
       "      <td>10.bmp</td>\n",
       "      <td>32</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[138, 150, 152], [166, 180, 192], [125, 144,...</td>\n",
       "      <td>0</td>\n",
       "      <td>100.bmp</td>\n",
       "      <td>114</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[220, 223, 238], [209, 213, 231], [194, 200,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1000.bmp</td>\n",
       "      <td>178</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>[[[139, 110, 190], [136, 107, 186], [139, 112,...</td>\n",
       "      <td>1</td>\n",
       "      <td>sample_picture_2014-02-17_18-39-00.jpg</td>\n",
       "      <td>103</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>[[[33, 20, 36], [35, 22, 38], [36, 22, 40], [3...</td>\n",
       "      <td>1</td>\n",
       "      <td>sample_picture_2014-02-17_18-39-22.jpg</td>\n",
       "      <td>75</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6335</th>\n",
       "      <td>[[[33, 20, 36], [35, 22, 38], [36, 22, 40], [3...</td>\n",
       "      <td>1</td>\n",
       "      <td>sample_picture_2014-02-17_18-39-30.jpg</td>\n",
       "      <td>75</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6336</th>\n",
       "      <td>[[[67, 51, 104], [69, 53, 106], [72, 55, 112],...</td>\n",
       "      <td>1</td>\n",
       "      <td>sample_picture_2014-02-17_18-42-17.jpg</td>\n",
       "      <td>91</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6337</th>\n",
       "      <td>[[[179, 130, 184], [179, 133, 186], [182, 135,...</td>\n",
       "      <td>1</td>\n",
       "      <td>sample_picture_2014-02-17_18-42-31.jpg</td>\n",
       "      <td>122</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6338 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Image  Class  \\\n",
       "0     [[[69, 73, 78], [73, 77, 82], [74, 78, 83], [7...      0   \n",
       "1     [[[116, 117, 121], [116, 117, 121], [116, 115,...      0   \n",
       "2     [[[57, 58, 56], [57, 58, 56], [64, 65, 63], [7...      0   \n",
       "3     [[[138, 150, 152], [166, 180, 192], [125, 144,...      0   \n",
       "4     [[[220, 223, 238], [209, 213, 231], [194, 200,...      0   \n",
       "...                                                 ...    ...   \n",
       "6333  [[[139, 110, 190], [136, 107, 186], [139, 112,...      1   \n",
       "6334  [[[33, 20, 36], [35, 22, 38], [36, 22, 40], [3...      1   \n",
       "6335  [[[33, 20, 36], [35, 22, 38], [36, 22, 40], [3...      1   \n",
       "6336  [[[67, 51, 104], [69, 53, 106], [72, 55, 112],...      1   \n",
       "6337  [[[179, 130, 184], [179, 133, 186], [182, 135,...      1   \n",
       "\n",
       "                                    FileName  Height  Width  \n",
       "0                                      0.bmp     144    264  \n",
       "1                                      1.bmp      76    220  \n",
       "2                                     10.bmp      32    456  \n",
       "3                                    100.bmp     114    158  \n",
       "4                                   1000.bmp     178    318  \n",
       "...                                      ...     ...    ...  \n",
       "6333  sample_picture_2014-02-17_18-39-00.jpg     103    310  \n",
       "6334  sample_picture_2014-02-17_18-39-22.jpg      75    226  \n",
       "6335  sample_picture_2014-02-17_18-39-30.jpg      75    226  \n",
       "6336  sample_picture_2014-02-17_18-42-17.jpg      91    273  \n",
       "6337  sample_picture_2014-02-17_18-42-31.jpg     122    366  \n",
       "\n",
       "[6338 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data loading\n",
    "data = pd.DataFrame(columns=['Image', 'Class', 'FileName'])\n",
    "\n",
    "for data_dir in sorted(os.listdir(r\"/media/romes_papa/4116c49e-4877-48e1-938d-e7fb6cc948ea/romes_papa/Datasets/license_plates/Nums_data\")):\n",
    "    for file in sorted(os.listdir(fr\"/media/romes_papa/4116c49e-4877-48e1-938d-e7fb6cc948ea/romes_papa/Datasets/license_plates/Nums_data/{data_dir}\")):\n",
    "        \n",
    "        img_path = fr\"/media/romes_papa/4116c49e-4877-48e1-938d-e7fb6cc948ea/romes_papa/Datasets/license_plates/Nums_data/{data_dir}/{file}\"\n",
    "        img = cv.imread(img_path, cv.IMREAD_COLOR)\n",
    "        \n",
    "        data = pd.concat([\n",
    "            data,\n",
    "            pd.DataFrame(data=[[img, data_dir, file]],\n",
    "                         columns=['Image', 'Class', 'FileName'])\n",
    "        ])\n",
    "\n",
    "data.index = pd.RangeIndex(data.shape[0])\n",
    "\n",
    "data['Height'] = data.Image.apply(lambda img: img.shape[0])\n",
    "data['Width']  = data.Image.apply(lambda img: img.shape[1])\n",
    "\n",
    "data.replace(to_replace = {'Class': {'Negative': 0, 'NumBase': 1}}, inplace=True, regex = True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average image height: 130.92 px\n",
      "Average image  width: 320.84 px\n"
     ]
    }
   ],
   "source": [
    "print(f'Average image height: {np.round(data.Height.mean(), 2)} px')\n",
    "print(f'Average image  width: {np.round(data.Width .mean(), 2)} px')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Class</th>\n",
       "      <th>FileName</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[69, 73, 78], [72, 76, 81], [73, 77, 82], [7...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.bmp</td>\n",
       "      <td>130</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[116, 117, 121], [116, 117, 121], [116, 116,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.bmp</td>\n",
       "      <td>130</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[57, 58, 56], [61, 62, 60], [71, 75, 69], [7...</td>\n",
       "      <td>0</td>\n",
       "      <td>10.bmp</td>\n",
       "      <td>130</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[138, 150, 152], [145, 157, 161], [159, 172,...</td>\n",
       "      <td>0</td>\n",
       "      <td>100.bmp</td>\n",
       "      <td>130</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[221, 224, 239], [208, 211, 229], [191, 197,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1000.bmp</td>\n",
       "      <td>130</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6333</th>\n",
       "      <td>[[[139, 110, 190], [136, 107, 186], [139, 112,...</td>\n",
       "      <td>1</td>\n",
       "      <td>sample_picture_2014-02-17_18-39-00.jpg</td>\n",
       "      <td>130</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>[[[33, 20, 36], [34, 21, 37], [35, 22, 38], [3...</td>\n",
       "      <td>1</td>\n",
       "      <td>sample_picture_2014-02-17_18-39-22.jpg</td>\n",
       "      <td>130</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6335</th>\n",
       "      <td>[[[33, 20, 36], [34, 21, 37], [35, 22, 38], [3...</td>\n",
       "      <td>1</td>\n",
       "      <td>sample_picture_2014-02-17_18-39-30.jpg</td>\n",
       "      <td>130</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6336</th>\n",
       "      <td>[[[67, 51, 104], [69, 52, 105], [71, 54, 110],...</td>\n",
       "      <td>1</td>\n",
       "      <td>sample_picture_2014-02-17_18-42-17.jpg</td>\n",
       "      <td>130</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6337</th>\n",
       "      <td>[[[179, 130, 184], [180, 133, 187], [181, 136,...</td>\n",
       "      <td>1</td>\n",
       "      <td>sample_picture_2014-02-17_18-42-31.jpg</td>\n",
       "      <td>130</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6338 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Image  Class  \\\n",
       "0     [[[69, 73, 78], [72, 76, 81], [73, 77, 82], [7...      0   \n",
       "1     [[[116, 117, 121], [116, 117, 121], [116, 116,...      0   \n",
       "2     [[[57, 58, 56], [61, 62, 60], [71, 75, 69], [7...      0   \n",
       "3     [[[138, 150, 152], [145, 157, 161], [159, 172,...      0   \n",
       "4     [[[221, 224, 239], [208, 211, 229], [191, 197,...      0   \n",
       "...                                                 ...    ...   \n",
       "6333  [[[139, 110, 190], [136, 107, 186], [139, 112,...      1   \n",
       "6334  [[[33, 20, 36], [34, 21, 37], [35, 22, 38], [3...      1   \n",
       "6335  [[[33, 20, 36], [34, 21, 37], [35, 22, 38], [3...      1   \n",
       "6336  [[[67, 51, 104], [69, 52, 105], [71, 54, 110],...      1   \n",
       "6337  [[[179, 130, 184], [180, 133, 187], [181, 136,...      1   \n",
       "\n",
       "                                    FileName  Height  Width  \n",
       "0                                      0.bmp     130    320  \n",
       "1                                      1.bmp     130    320  \n",
       "2                                     10.bmp     130    320  \n",
       "3                                    100.bmp     130    320  \n",
       "4                                   1000.bmp     130    320  \n",
       "...                                      ...     ...    ...  \n",
       "6333  sample_picture_2014-02-17_18-39-00.jpg     130    320  \n",
       "6334  sample_picture_2014-02-17_18-39-22.jpg     130    320  \n",
       "6335  sample_picture_2014-02-17_18-39-30.jpg     130    320  \n",
       "6336  sample_picture_2014-02-17_18-42-17.jpg     130    320  \n",
       "6337  sample_picture_2014-02-17_18-42-31.jpg     130    320  \n",
       "\n",
       "[6338 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Image = data.Image.apply(lambda img: cv.resize(img, dsize=(320, 130)))\n",
    "\n",
    "data['Height'] = data.Image.apply(lambda img: img.shape[0])\n",
    "data['Width']  = data.Image.apply(lambda img: img.shape[1])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for image, target in zip(data.Image, data.Class):\n",
    "    X.append(image)\n",
    "    y.append(target)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "y = utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.1, random_state=228)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (5704, 130, 320, 3)\n",
      "X_test.shape = (634, 130, 320, 3)\n",
      "y_train.shape = (5704, 2)\n",
      "y_test.shape = (634, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train.shape = {X_train.shape}')\n",
    "print(f'X_test.shape = {X_test.shape}')\n",
    "print(f'y_train.shape = {y_train.shape}')\n",
    "print(f'y_test.shape = {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.01,\n",
    "    width_shift_range=0.01,\n",
    "    height_shift_range=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 130, 320, 32)      2432      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 130, 320, 32)      25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 65, 160, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 65, 160, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 65, 160, 32)       25632     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 65, 160, 32)       25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 80, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 80, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 80, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 80, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 40, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 40, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 20, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10240)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2621696   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 2,830,818\n",
      "Trainable params: 2,830,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model creating\n",
    "num_classes = data.Class.unique().shape[0]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='Same',\n",
    "                 activation='relu', input_shape=(130, 320, 3)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='Same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='Same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='Same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('micro_detector.hdf5',\n",
    "                             monitor='val_accuracy',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                                            patience=3,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6338, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 40\n",
    "np.unique(y, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.9770 - accuracy: 0.8667\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.96530, saving model to micro_detector.hdf5\n",
      "142/142 [==============================] - 47s 332ms/step - loss: 0.9770 - accuracy: 0.8667 - val_loss: 0.2083 - val_accuracy: 0.9653 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.1699 - accuracy: 0.9500\n",
      "Epoch 00002: val_accuracy improved from 0.96530 to 0.97792, saving model to micro_detector.hdf5\n",
      "142/142 [==============================] - 38s 266ms/step - loss: 0.1699 - accuracy: 0.9500 - val_loss: 0.1117 - val_accuracy: 0.9779 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.1262 - accuracy: 0.9629\n",
      "Epoch 00003: val_accuracy did not improve from 0.97792\n",
      "142/142 [==============================] - 36s 253ms/step - loss: 0.1262 - accuracy: 0.9629 - val_loss: 0.0921 - val_accuracy: 0.9779 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.9633\n",
      "Epoch 00004: val_accuracy did not improve from 0.97792\n",
      "142/142 [==============================] - 38s 265ms/step - loss: 0.1101 - accuracy: 0.9633 - val_loss: 0.1079 - val_accuracy: 0.9716 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.1092 - accuracy: 0.9620\n",
      "Epoch 00005: val_accuracy improved from 0.97792 to 0.98580, saving model to micro_detector.hdf5\n",
      "142/142 [==============================] - 38s 265ms/step - loss: 0.1092 - accuracy: 0.9620 - val_loss: 0.0612 - val_accuracy: 0.9858 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0886 - accuracy: 0.9696\n",
      "Epoch 00006: val_accuracy did not improve from 0.98580\n",
      "142/142 [==============================] - 37s 261ms/step - loss: 0.0886 - accuracy: 0.9696 - val_loss: 0.0861 - val_accuracy: 0.9763 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0791 - accuracy: 0.9732\n",
      "Epoch 00007: val_accuracy improved from 0.98580 to 0.98896, saving model to micro_detector.hdf5\n",
      "142/142 [==============================] - 37s 262ms/step - loss: 0.0791 - accuracy: 0.9732 - val_loss: 0.0426 - val_accuracy: 0.9890 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9767\n",
      "Epoch 00008: val_accuracy did not improve from 0.98896\n",
      "142/142 [==============================] - 36s 257ms/step - loss: 0.0658 - accuracy: 0.9767 - val_loss: 0.0517 - val_accuracy: 0.9874 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0813 - accuracy: 0.9740\n",
      "Epoch 00009: val_accuracy did not improve from 0.98896\n",
      "142/142 [==============================] - 36s 257ms/step - loss: 0.0813 - accuracy: 0.9740 - val_loss: 0.0602 - val_accuracy: 0.9748 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 0.9779\n",
      "Epoch 00010: val_accuracy did not improve from 0.98896\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "142/142 [==============================] - 36s 254ms/step - loss: 0.0638 - accuracy: 0.9779 - val_loss: 0.0420 - val_accuracy: 0.9842 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9808\n",
      "Epoch 00011: val_accuracy did not improve from 0.98896\n",
      "142/142 [==============================] - 40s 281ms/step - loss: 0.0524 - accuracy: 0.9808 - val_loss: 0.0501 - val_accuracy: 0.9826 - lr: 5.0000e-04\n",
      "Epoch 12/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9825\n",
      "Epoch 00012: val_accuracy improved from 0.98896 to 0.99054, saving model to micro_detector.hdf5\n",
      "142/142 [==============================] - 39s 277ms/step - loss: 0.0457 - accuracy: 0.9825 - val_loss: 0.0297 - val_accuracy: 0.9905 - lr: 5.0000e-04\n",
      "Epoch 13/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0458 - accuracy: 0.9831\n",
      "Epoch 00013: val_accuracy did not improve from 0.99054\n",
      "142/142 [==============================] - 38s 267ms/step - loss: 0.0458 - accuracy: 0.9831 - val_loss: 0.0307 - val_accuracy: 0.9874 - lr: 5.0000e-04\n",
      "Epoch 14/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9859\n",
      "Epoch 00014: val_accuracy did not improve from 0.99054\n",
      "142/142 [==============================] - 36s 256ms/step - loss: 0.0385 - accuracy: 0.9859 - val_loss: 0.0426 - val_accuracy: 0.9858 - lr: 5.0000e-04\n",
      "Epoch 15/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9875\n",
      "Epoch 00015: val_accuracy did not improve from 0.99054\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "142/142 [==============================] - 36s 256ms/step - loss: 0.0416 - accuracy: 0.9875 - val_loss: 0.0410 - val_accuracy: 0.9826 - lr: 5.0000e-04\n",
      "Epoch 16/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9894\n",
      "Epoch 00016: val_accuracy did not improve from 0.99054\n",
      "142/142 [==============================] - 36s 251ms/step - loss: 0.0275 - accuracy: 0.9894 - val_loss: 0.0255 - val_accuracy: 0.9905 - lr: 2.5000e-04\n",
      "Epoch 17/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 0.9892\n",
      "Epoch 00017: val_accuracy did not improve from 0.99054\n",
      "142/142 [==============================] - 36s 255ms/step - loss: 0.0267 - accuracy: 0.9892 - val_loss: 0.0293 - val_accuracy: 0.9890 - lr: 2.5000e-04\n",
      "Epoch 18/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9928\n",
      "Epoch 00018: val_accuracy improved from 0.99054 to 0.99527, saving model to micro_detector.hdf5\n",
      "142/142 [==============================] - 38s 268ms/step - loss: 0.0237 - accuracy: 0.9928 - val_loss: 0.0173 - val_accuracy: 0.9953 - lr: 2.5000e-04\n",
      "Epoch 19/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9912\n",
      "Epoch 00019: val_accuracy did not improve from 0.99527\n",
      "142/142 [==============================] - 38s 265ms/step - loss: 0.0249 - accuracy: 0.9912 - val_loss: 0.0300 - val_accuracy: 0.9905 - lr: 2.5000e-04\n",
      "Epoch 20/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9919\n",
      "Epoch 00020: val_accuracy did not improve from 0.99527\n",
      "142/142 [==============================] - 38s 264ms/step - loss: 0.0266 - accuracy: 0.9919 - val_loss: 0.0181 - val_accuracy: 0.9953 - lr: 2.5000e-04\n",
      "Epoch 21/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 0.9906\n",
      "Epoch 00021: val_accuracy did not improve from 0.99527\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "142/142 [==============================] - 39s 275ms/step - loss: 0.0257 - accuracy: 0.9906 - val_loss: 0.0346 - val_accuracy: 0.9905 - lr: 2.5000e-04\n",
      "Epoch 22/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9931\n",
      "Epoch 00022: val_accuracy did not improve from 0.99527\n",
      "142/142 [==============================] - 36s 252ms/step - loss: 0.0191 - accuracy: 0.9931 - val_loss: 0.0248 - val_accuracy: 0.9905 - lr: 1.2500e-04\n",
      "Epoch 23/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9933\n",
      "Epoch 00023: val_accuracy did not improve from 0.99527\n",
      "142/142 [==============================] - 41s 290ms/step - loss: 0.0166 - accuracy: 0.9933 - val_loss: 0.0210 - val_accuracy: 0.9905 - lr: 1.2500e-04\n",
      "Epoch 24/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9919\n",
      "Epoch 00024: val_accuracy did not improve from 0.99527\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "142/142 [==============================] - 42s 297ms/step - loss: 0.0194 - accuracy: 0.9919 - val_loss: 0.0255 - val_accuracy: 0.9905 - lr: 1.2500e-04\n",
      "Epoch 25/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9942\n",
      "Epoch 00025: val_accuracy did not improve from 0.99527\n",
      "142/142 [==============================] - 42s 297ms/step - loss: 0.0159 - accuracy: 0.9942 - val_loss: 0.0186 - val_accuracy: 0.9890 - lr: 6.2500e-05\n",
      "Epoch 26/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9949\n",
      "Epoch 00026: val_accuracy did not improve from 0.99527\n",
      "142/142 [==============================] - 42s 297ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.0285 - val_accuracy: 0.9905 - lr: 6.2500e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9966\n",
      "Epoch 00027: val_accuracy did not improve from 0.99527\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "142/142 [==============================] - 42s 298ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.0215 - val_accuracy: 0.9905 - lr: 6.2500e-05\n",
      "Epoch 28/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9956\n",
      "Epoch 00028: val_accuracy did not improve from 0.99527\n",
      "142/142 [==============================] - 42s 296ms/step - loss: 0.0113 - accuracy: 0.9956 - val_loss: 0.0232 - val_accuracy: 0.9905 - lr: 3.1250e-05\n",
      "Epoch 29/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9958\n",
      "Epoch 00029: val_accuracy did not improve from 0.99527\n",
      "142/142 [==============================] - 42s 296ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.0218 - val_accuracy: 0.9905 - lr: 3.1250e-05\n",
      "Epoch 30/30\n",
      "142/142 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9935\n",
      "Epoch 00030: val_accuracy did not improve from 0.99527\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "142/142 [==============================] - 42s 298ms/step - loss: 0.0163 - accuracy: 0.9935 - val_loss: 0.0216 - val_accuracy: 0.9921 - lr: 3.1250e-05\n",
      "--- 1197.6034541130066 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                    epochs=30,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    steps_per_epoch=(X_train.shape[0] // batch_size),\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpoint, learning_rate_reduction]\n",
    "                    )\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
