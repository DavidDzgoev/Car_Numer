{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,\\\n",
    "                                    Conv2D,\\\n",
    "                                    MaxPooling2D,\\\n",
    "                                    Dropout,\\\n",
    "                                    Flatten\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,\\\n",
    "                                       ModelCheckpoint\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>FileName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[229, 229, 229], [231, 231, 231], [233, 233,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[231, 231, 231], [230, 230, 230], [229, 229,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1 (2).bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[115, 115, 115], [136, 136, 136], [151, 151,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[102, 102, 102], [95, 95, 95], [83, 83, 83],...</td>\n",
       "      <td>0</td>\n",
       "      <td>10 (2).bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[113, 113, 113], [109, 109, 109], [112, 112,...</td>\n",
       "      <td>0</td>\n",
       "      <td>10.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18533</th>\n",
       "      <td>[[[125, 125, 125], [126, 126, 126], [128, 128,...</td>\n",
       "      <td>9</td>\n",
       "      <td>95.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18534</th>\n",
       "      <td>[[[177, 177, 177], [177, 177, 177], [178, 178,...</td>\n",
       "      <td>9</td>\n",
       "      <td>96.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18535</th>\n",
       "      <td>[[[240, 240, 240], [240, 240, 240], [241, 241,...</td>\n",
       "      <td>9</td>\n",
       "      <td>97.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18536</th>\n",
       "      <td>[[[168, 168, 168], [178, 178, 178], [191, 191,...</td>\n",
       "      <td>9</td>\n",
       "      <td>98.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18537</th>\n",
       "      <td>[[[160, 160, 160], [157, 157, 157], [149, 149,...</td>\n",
       "      <td>9</td>\n",
       "      <td>99.bmp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18538 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Image Symbol    FileName\n",
       "0      [[[229, 229, 229], [231, 231, 231], [233, 233,...      0       0.bmp\n",
       "1      [[[231, 231, 231], [230, 230, 230], [229, 229,...      0   1 (2).bmp\n",
       "2      [[[115, 115, 115], [136, 136, 136], [151, 151,...      0       1.bmp\n",
       "3      [[[102, 102, 102], [95, 95, 95], [83, 83, 83],...      0  10 (2).bmp\n",
       "4      [[[113, 113, 113], [109, 109, 109], [112, 112,...      0      10.bmp\n",
       "...                                                  ...    ...         ...\n",
       "18533  [[[125, 125, 125], [126, 126, 126], [128, 128,...      9      95.bmp\n",
       "18534  [[[177, 177, 177], [177, 177, 177], [178, 178,...      9      96.bmp\n",
       "18535  [[[240, 240, 240], [240, 240, 240], [241, 241,...      9      97.bmp\n",
       "18536  [[[168, 168, 168], [178, 178, 178], [191, 191,...      9      98.bmp\n",
       "18537  [[[160, 160, 160], [157, 157, 157], [149, 149,...      9      99.bmp\n",
       "\n",
       "[18538 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data loading\n",
    "data = pd.DataFrame(columns=['Image', 'Symbol', 'FileName'])\n",
    "\n",
    "for data_dir in sorted(os.listdir(r\"/media/romes_papa/4116c49e-4877-48e1-938d-e7fb6cc948ea/romes_papa/Datasets/license_plates/car_nums_data\")):\n",
    "    for file in sorted(os.listdir(fr\"/media/romes_papa/4116c49e-4877-48e1-938d-e7fb6cc948ea/romes_papa/Datasets/license_plates/car_nums_data/{data_dir}\")):\n",
    "        \n",
    "        img_path = fr\"/media/romes_papa/4116c49e-4877-48e1-938d-e7fb6cc948ea/romes_papa/Datasets/license_plates/car_nums_data/{data_dir}/{file}\"\n",
    "        img = cv.imread(img_path, cv.IMREAD_COLOR)\n",
    "        \n",
    "        data = pd.concat([\n",
    "            data,\n",
    "            pd.DataFrame(data=[[img, int(data_dir), file]],\n",
    "                         columns=['Image', 'Symbol', 'FileName'])\n",
    "        ])\n",
    "\n",
    "data.index = pd.RangeIndex(data.shape[0])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average image height: 53.14 px\n",
      "Average image  width: 45.51 px\n"
     ]
    }
   ],
   "source": [
    "# converting images to same shape\n",
    "data['Height'] = data.Image.apply(lambda img: img.shape[0])\n",
    "data['Width']  = data.Image.apply(lambda img: img.shape[1])\n",
    "\n",
    "print(f'Average image height: {np.round(data.Height.mean(), 2)} px')\n",
    "print(f'Average image  width: {np.round(data.Width .mean(), 2)} px')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>FileName</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[229, 229, 229], [231, 231, 231], [233, 233,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.bmp</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[231, 231, 231], [230, 230, 230], [229, 229,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1 (2).bmp</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[115, 115, 115], [136, 136, 136], [151, 151,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.bmp</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[102, 102, 102], [95, 95, 95], [83, 83, 83],...</td>\n",
       "      <td>0</td>\n",
       "      <td>10 (2).bmp</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[113, 113, 113], [109, 109, 109], [112, 112,...</td>\n",
       "      <td>0</td>\n",
       "      <td>10.bmp</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18533</th>\n",
       "      <td>[[[125, 125, 125], [126, 126, 126], [128, 128,...</td>\n",
       "      <td>9</td>\n",
       "      <td>95.bmp</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18534</th>\n",
       "      <td>[[[176, 176, 176], [177, 177, 177], [177, 177,...</td>\n",
       "      <td>9</td>\n",
       "      <td>96.bmp</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18535</th>\n",
       "      <td>[[[240, 240, 240], [240, 240, 240], [241, 241,...</td>\n",
       "      <td>9</td>\n",
       "      <td>97.bmp</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18536</th>\n",
       "      <td>[[[169, 169, 169], [179, 179, 179], [192, 192,...</td>\n",
       "      <td>9</td>\n",
       "      <td>98.bmp</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18537</th>\n",
       "      <td>[[[160, 160, 160], [157, 157, 157], [149, 149,...</td>\n",
       "      <td>9</td>\n",
       "      <td>99.bmp</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18538 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Image Symbol    FileName  \\\n",
       "0      [[[229, 229, 229], [231, 231, 231], [233, 233,...      0       0.bmp   \n",
       "1      [[[231, 231, 231], [230, 230, 230], [229, 229,...      0   1 (2).bmp   \n",
       "2      [[[115, 115, 115], [136, 136, 136], [151, 151,...      0       1.bmp   \n",
       "3      [[[102, 102, 102], [95, 95, 95], [83, 83, 83],...      0  10 (2).bmp   \n",
       "4      [[[113, 113, 113], [109, 109, 109], [112, 112,...      0      10.bmp   \n",
       "...                                                  ...    ...         ...   \n",
       "18533  [[[125, 125, 125], [126, 126, 126], [128, 128,...      9      95.bmp   \n",
       "18534  [[[176, 176, 176], [177, 177, 177], [177, 177,...      9      96.bmp   \n",
       "18535  [[[240, 240, 240], [240, 240, 240], [241, 241,...      9      97.bmp   \n",
       "18536  [[[169, 169, 169], [179, 179, 179], [192, 192,...      9      98.bmp   \n",
       "18537  [[[160, 160, 160], [157, 157, 157], [149, 149,...      9      99.bmp   \n",
       "\n",
       "       Height  Width  \n",
       "0          50     40  \n",
       "1          50     40  \n",
       "2          50     40  \n",
       "3          50     40  \n",
       "4          50     40  \n",
       "...       ...    ...  \n",
       "18533      50     40  \n",
       "18534      50     40  \n",
       "18535      50     40  \n",
       "18536      50     40  \n",
       "18537      50     40  \n",
       "\n",
       "[18538 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resizing to the same shape\n",
    "\n",
    "data.Image = data.Image.apply(lambda img: cv.resize(img, dsize=(40, 50)))\n",
    "\n",
    "data['Height'] = data.Image.apply(lambda img: img.shape[0])\n",
    "data['Width']  = data.Image.apply(lambda img: img.shape[1])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdaf6774e20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data.loc[np.random.randint(data.shape[0]), 'Image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for image, target in zip(data.Image, data.Symbol):\n",
    "    X.append(image)\n",
    "    y.append(target)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "y = utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 228\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (16684, 50, 40, 3)\n",
      "X_test.shape = (1854, 50, 40, 3)\n",
      "y_train.shape = (16684, 23)\n",
      "y_test.shape = (1854, 23)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train.shape = {X_train.shape}')\n",
    "print(f'X_test.shape = {X_test.shape}')\n",
    "print(f'y_train.shape = {y_train.shape}')\n",
    "print(f'y_test.shape = {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand_index = np.random.randint(X_train.shape[0])\n",
    "plt.imshow(X_train[rand_index])\n",
    "print(y_train[rand_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    zoom_range=0.01,\n",
    "    width_shift_range=0.01,\n",
    "    height_shift_range=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 50, 40, 32)        2432      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 50, 40, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 25, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 25, 20, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 20, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 7680)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1966336   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 23)                5911      \n",
      "=================================================================\n",
      "Total params: 2,055,735\n",
      "Trainable params: 2,055,735\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model creating\n",
    "num_classes = data.Symbol.unique().shape[0]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='Same',\n",
    "                 activation='relu', input_shape=(50, 40, 3)))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='Same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same',\n",
    "                 activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=23, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('syms_recognitor.hdf5',\n",
    "                             monitor='val_accuracy',\n",
    "                             sasve_best_only=True,\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                                            patience=3,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18538, 23)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 96\n",
    "np.unique(y, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "172/173 [============================>.] - ETA: 0s - loss: 4.0129 - accuracy: 0.7484\n",
      "Epoch 00001: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 12s 71ms/step - loss: 3.9904 - accuracy: 0.7497 - val_loss: 0.0670 - val_accuracy: 0.9892 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "172/173 [============================>.] - ETA: 0s - loss: 0.1121 - accuracy: 0.9742\n",
      "Epoch 00002: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 9s 52ms/step - loss: 0.1122 - accuracy: 0.9741 - val_loss: 0.0530 - val_accuracy: 0.9898 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.9785\n",
      "Epoch 00003: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 9s 52ms/step - loss: 0.0896 - accuracy: 0.9785 - val_loss: 0.0516 - val_accuracy: 0.9908 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.9825\n",
      "Epoch 00004: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 9s 52ms/step - loss: 0.0719 - accuracy: 0.9825 - val_loss: 0.0540 - val_accuracy: 0.9914 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "172/173 [============================>.] - ETA: 0s - loss: 0.0625 - accuracy: 0.9847\n",
      "Epoch 00005: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 9s 51ms/step - loss: 0.0625 - accuracy: 0.9846 - val_loss: 0.0659 - val_accuracy: 0.9898 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 0.9863\n",
      "Epoch 00006: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 9s 52ms/step - loss: 0.0545 - accuracy: 0.9863 - val_loss: 0.0591 - val_accuracy: 0.9903 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.9876\n",
      "Epoch 00007: saving model to syms_recognitor.hdf5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "173/173 [==============================] - 9s 52ms/step - loss: 0.0551 - accuracy: 0.9876 - val_loss: 0.0500 - val_accuracy: 0.9908 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9896\n",
      "Epoch 00008: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 9s 52ms/step - loss: 0.0411 - accuracy: 0.9896 - val_loss: 0.0512 - val_accuracy: 0.9908 - lr: 5.0000e-04\n",
      "Epoch 9/30\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9917\n",
      "Epoch 00009: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 9s 52ms/step - loss: 0.0340 - accuracy: 0.9917 - val_loss: 0.0496 - val_accuracy: 0.9924 - lr: 5.0000e-04\n",
      "Epoch 10/30\n",
      "172/173 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9926\n",
      "Epoch 00010: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 9s 52ms/step - loss: 0.0290 - accuracy: 0.9926 - val_loss: 0.0592 - val_accuracy: 0.9919 - lr: 5.0000e-04\n",
      "Epoch 11/30\n",
      "172/173 [============================>.] - ETA: 0s - loss: 0.0313 - accuracy: 0.9924\n",
      "Epoch 00011: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 9s 52ms/step - loss: 0.0316 - accuracy: 0.9924 - val_loss: 0.0663 - val_accuracy: 0.9924 - lr: 5.0000e-04\n",
      "Epoch 12/30\n",
      "172/173 [============================>.] - ETA: 0s - loss: 0.0257 - accuracy: 0.9931\n",
      "Epoch 00012: saving model to syms_recognitor.hdf5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "173/173 [==============================] - 9s 53ms/step - loss: 0.0257 - accuracy: 0.9930 - val_loss: 0.0526 - val_accuracy: 0.9903 - lr: 5.0000e-04\n",
      "Epoch 13/30\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9945\n",
      "Epoch 00013: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 9s 52ms/step - loss: 0.0203 - accuracy: 0.9945 - val_loss: 0.0582 - val_accuracy: 0.9914 - lr: 2.5000e-04\n",
      "Epoch 14/30\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9939\n",
      "Epoch 00014: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 9s 52ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.0563 - val_accuracy: 0.9919 - lr: 2.5000e-04\n",
      "Epoch 15/30\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9951\n",
      "Epoch 00015: saving model to syms_recognitor.hdf5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "173/173 [==============================] - 9s 52ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.0609 - val_accuracy: 0.9919 - lr: 2.5000e-04\n",
      "Epoch 16/30\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9961\n",
      "Epoch 00016: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 9s 52ms/step - loss: 0.0164 - accuracy: 0.9961 - val_loss: 0.0614 - val_accuracy: 0.9908 - lr: 1.2500e-04\n",
      "Epoch 17/30\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9954\n",
      "Epoch 00017: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 9s 52ms/step - loss: 0.0159 - accuracy: 0.9954 - val_loss: 0.0548 - val_accuracy: 0.9919 - lr: 1.2500e-04\n",
      "Epoch 18/30\n",
      "172/173 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9956\n",
      "Epoch 00018: saving model to syms_recognitor.hdf5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "173/173 [==============================] - 9s 52ms/step - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.0608 - val_accuracy: 0.9914 - lr: 1.2500e-04\n",
      "Epoch 19/30\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9963\n",
      "Epoch 00019: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 9s 52ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.0571 - val_accuracy: 0.9914 - lr: 6.2500e-05\n",
      "Epoch 20/30\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9963\n",
      "Epoch 00020: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 9s 52ms/step - loss: 0.0135 - accuracy: 0.9963 - val_loss: 0.0596 - val_accuracy: 0.9908 - lr: 6.2500e-05\n",
      "Epoch 21/30\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9970\n",
      "Epoch 00021: saving model to syms_recognitor.hdf5\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "173/173 [==============================] - 9s 52ms/step - loss: 0.0121 - accuracy: 0.9970 - val_loss: 0.0615 - val_accuracy: 0.9914 - lr: 6.2500e-05\n",
      "Epoch 22/30\n",
      "172/173 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9961\n",
      "Epoch 00022: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 9s 52ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.0595 - val_accuracy: 0.9914 - lr: 3.1250e-05\n",
      "Epoch 23/30\n",
      "172/173 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9964\n",
      "Epoch 00023: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 9s 52ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.0594 - val_accuracy: 0.9919 - lr: 3.1250e-05\n",
      "Epoch 24/30\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9962\n",
      "Epoch 00024: saving model to syms_recognitor.hdf5\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "173/173 [==============================] - 9s 53ms/step - loss: 0.0137 - accuracy: 0.9962 - val_loss: 0.0616 - val_accuracy: 0.9919 - lr: 3.1250e-05\n",
      "Epoch 25/30\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9964\n",
      "Epoch 00025: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 9s 53ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.0571 - val_accuracy: 0.9919 - lr: 1.5625e-05\n",
      "Epoch 26/30\n",
      "172/173 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9967\n",
      "Epoch 00026: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 9s 54ms/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 0.0598 - val_accuracy: 0.9914 - lr: 1.5625e-05\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/173 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9973\n",
      "Epoch 00027: saving model to syms_recognitor.hdf5\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "173/173 [==============================] - 9s 53ms/step - loss: 0.0100 - accuracy: 0.9973 - val_loss: 0.0590 - val_accuracy: 0.9919 - lr: 1.5625e-05\n",
      "Epoch 28/30\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9964\n",
      "Epoch 00028: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 9s 52ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.0590 - val_accuracy: 0.9919 - lr: 1.0000e-05\n",
      "Epoch 29/30\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9968\n",
      "Epoch 00029: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 10s 55ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0595 - val_accuracy: 0.9919 - lr: 1.0000e-05\n",
      "Epoch 30/30\n",
      "173/173 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9970\n",
      "Epoch 00030: saving model to syms_recognitor.hdf5\n",
      "173/173 [==============================] - 9s 53ms/step - loss: 0.0118 - accuracy: 0.9970 - val_loss: 0.0587 - val_accuracy: 0.9919 - lr: 1.0000e-05\n",
      "--- 285.88077902793884 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "                    epochs=30,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    steps_per_epoch=(X_train.shape[0] // batch_size),\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpoint, learning_rate_reduction]\n",
    "                    )\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
